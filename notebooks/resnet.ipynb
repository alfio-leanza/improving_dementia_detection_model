{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwt_path = \"/Users/alfioleanza/progetto_tesi/dataset-eeg/miltiadous_deriv_uV_d1.0s_o0.0s/cwt\"\n",
    "labels_path = \"/Users/alfioleanza/progetto_tesi/dataset-eeg/inference_20250327_171717/true_pred.csv\"\n",
    "\n",
    "data_split = {\n",
    "    \"train\": [37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21],\n",
    "    \"val\": [54, 55, 56, 57, 58, 59, 79, 80, 81, 82, 83, 22, 23, 24, 25, 26, 27, 28],\n",
    "    \"test\": [60, 61, 62, 63, 64, 65, 84, 85, 86, 87, 88, 29, 30, 31, 32, 33, 34, 35, 36]\n",
    "}\n",
    "\n",
    "df_labels = pd.read_csv(labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels['train_label'] = (df_labels['pred_label'] == df_labels['true_label']).astype(int)\n",
    "df_labels['train_label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crop_file</th>\n",
       "      <th>activation_values</th>\n",
       "      <th>dataset</th>\n",
       "      <th>softmax_values</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>true_label</th>\n",
       "      <th>original_rec</th>\n",
       "      <th>crop_start_sample</th>\n",
       "      <th>crop_end_sample</th>\n",
       "      <th>train_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000848.npy</td>\n",
       "      <td>[ 1.0532185 -1.5921667 -0.8496607]</td>\n",
       "      <td>training</td>\n",
       "      <td>[0.8195938  0.05817313 0.12223307]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sub-037</td>\n",
       "      <td>0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000849.npy</td>\n",
       "      <td>[ 0.8592405  -0.8918216  -0.32704002]</td>\n",
       "      <td>training</td>\n",
       "      <td>[0.67615795 0.1173739  0.20646815]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sub-037</td>\n",
       "      <td>500</td>\n",
       "      <td>999.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000850.npy</td>\n",
       "      <td>[ 0.89024836 -1.5663235  -0.599953  ]</td>\n",
       "      <td>training</td>\n",
       "      <td>[0.7627442  0.06538879 0.17186707]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sub-037</td>\n",
       "      <td>1000</td>\n",
       "      <td>1499.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000851.npy</td>\n",
       "      <td>[ 0.9642988  -1.5698762  -0.83838975]</td>\n",
       "      <td>training</td>\n",
       "      <td>[0.80374086 0.06375847 0.13250075]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sub-037</td>\n",
       "      <td>1500</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000852.npy</td>\n",
       "      <td>[ 0.9176249 -1.4399661 -0.5990748]</td>\n",
       "      <td>training</td>\n",
       "      <td>[0.76098704 0.07202587 0.1669871 ]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sub-037</td>\n",
       "      <td>2000</td>\n",
       "      <td>2499.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69789</th>\n",
       "      <td>00069084.npy</td>\n",
       "      <td>[-3.1664958  -1.7627978  -0.22231679]</td>\n",
       "      <td>validation</td>\n",
       "      <td>[0.04155363 0.16913258 0.78931385]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>sub-026</td>\n",
       "      <td>446500</td>\n",
       "      <td>446999.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69790</th>\n",
       "      <td>00069085.npy</td>\n",
       "      <td>[-1.5803745  -0.6570947  -0.06765006]</td>\n",
       "      <td>validation</td>\n",
       "      <td>[0.12412163 0.3124804  0.563398  ]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>sub-026</td>\n",
       "      <td>447000</td>\n",
       "      <td>447499.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69791</th>\n",
       "      <td>00069086.npy</td>\n",
       "      <td>[-0.6699866  -0.1551984  -0.40366274]</td>\n",
       "      <td>validation</td>\n",
       "      <td>[0.2513547 0.4205878 0.3280575]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>sub-026</td>\n",
       "      <td>447500</td>\n",
       "      <td>447999.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69792</th>\n",
       "      <td>00069087.npy</td>\n",
       "      <td>[-0.6042401  -0.30352032 -0.33559638]</td>\n",
       "      <td>validation</td>\n",
       "      <td>[0.27329725 0.36917832 0.35752445]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>sub-026</td>\n",
       "      <td>448000</td>\n",
       "      <td>448499.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69793</th>\n",
       "      <td>00069088.npy</td>\n",
       "      <td>[-1.4431906  -0.04802594 -0.5766928 ]</td>\n",
       "      <td>validation</td>\n",
       "      <td>[0.13487622 0.5443117  0.32081202]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>sub-026</td>\n",
       "      <td>448500</td>\n",
       "      <td>448999.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69794 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          crop_file                      activation_values     dataset  \\\n",
       "0      00000848.npy     [ 1.0532185 -1.5921667 -0.8496607]    training   \n",
       "1      00000849.npy  [ 0.8592405  -0.8918216  -0.32704002]    training   \n",
       "2      00000850.npy  [ 0.89024836 -1.5663235  -0.599953  ]    training   \n",
       "3      00000851.npy  [ 0.9642988  -1.5698762  -0.83838975]    training   \n",
       "4      00000852.npy     [ 0.9176249 -1.4399661 -0.5990748]    training   \n",
       "...             ...                                    ...         ...   \n",
       "69789  00069084.npy  [-3.1664958  -1.7627978  -0.22231679]  validation   \n",
       "69790  00069085.npy  [-1.5803745  -0.6570947  -0.06765006]  validation   \n",
       "69791  00069086.npy  [-0.6699866  -0.1551984  -0.40366274]  validation   \n",
       "69792  00069087.npy  [-0.6042401  -0.30352032 -0.33559638]  validation   \n",
       "69793  00069088.npy  [-1.4431906  -0.04802594 -0.5766928 ]  validation   \n",
       "\n",
       "                           softmax_values  pred_label  true_label  \\\n",
       "0      [0.8195938  0.05817313 0.12223307]           0           0   \n",
       "1      [0.67615795 0.1173739  0.20646815]           0           0   \n",
       "2      [0.7627442  0.06538879 0.17186707]           0           0   \n",
       "3      [0.80374086 0.06375847 0.13250075]           0           0   \n",
       "4      [0.76098704 0.07202587 0.1669871 ]           0           0   \n",
       "...                                   ...         ...         ...   \n",
       "69789  [0.04155363 0.16913258 0.78931385]           2           2   \n",
       "69790  [0.12412163 0.3124804  0.563398  ]           2           2   \n",
       "69791     [0.2513547 0.4205878 0.3280575]           1           2   \n",
       "69792  [0.27329725 0.36917832 0.35752445]           1           2   \n",
       "69793  [0.13487622 0.5443117  0.32081202]           1           2   \n",
       "\n",
       "      original_rec  crop_start_sample  crop_end_sample  train_label  \n",
       "0          sub-037                  0            499.0            1  \n",
       "1          sub-037                500            999.0            1  \n",
       "2          sub-037               1000           1499.0            1  \n",
       "3          sub-037               1500           1999.0            1  \n",
       "4          sub-037               2000           2499.0            1  \n",
       "...            ...                ...              ...          ...  \n",
       "69789      sub-026             446500         446999.0            1  \n",
       "69790      sub-026             447000         447499.0            1  \n",
       "69791      sub-026             447500         447999.0            0  \n",
       "69792      sub-026             448000         448499.0            0  \n",
       "69793      sub-026             448500         448999.0            0  \n",
       "\n",
       "[69794 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CWT_Dataset(Dataset):\n",
    "    def __init__(self, file_list, labels, root_dir):\n",
    "        self.file_list = file_list\n",
    "        self.labels = labels\n",
    "        self.root_dir = root_dir\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_list[idx]\n",
    "        label = self.labels[idx]\n",
    "        file_path = os.path.join(self.root_dir, file_name)\n",
    "        cwt_data = np.load(file_path)\n",
    "        cwt_data = torch.tensor(cwt_data, dtype=torch.float32)\n",
    "        cwt_data = cwt_data.permute(2, 0, 1)\n",
    "        return cwt_data, label\n",
    "\n",
    "def create_dataloader(split, batch_size=16):\n",
    "    subset = df_labels[df_labels['original_rec'].isin([f\"sub-{s:03d}\" for s in data_split[split]])]\n",
    "    file_list = list(subset[\"crop_file\"])\n",
    "    labels = list(subset[\"train_label\"])\n",
    "    dataset = CWT_Dataset(file_list, labels, cwt_path)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "class ResNet18_19Channels(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(ResNet18_19Channels, self).__init__()\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        \n",
    "        self.model.conv1 = nn.Conv2d(19, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        \n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "def train_model(model, train_loader, val_loader, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        val_acc = evaluate_model(model, val_loader)\n",
    "        print(f\"Epoch {epoch+1}: Loss={running_loss/len(train_loader):.4f}, Train Acc={100.*correct/total:.2f}%, Val Acc={val_acc:.2f}%\")\n",
    "\n",
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    return 100. * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = create_dataloader(\"train\")\n",
    "val_loader = create_dataloader(\"val\")\n",
    "test_loader = create_dataloader(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alfioleanza/progetto_tesi/venv/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/alfioleanza/progetto_tesi/venv/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ResNet18_19Channels(num_classes=2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  16%|█▋        | 414/2530 [13:17<1:07:53,  1.93s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 44\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, epochs)\u001b[0m\n\u001b[1;32m     42\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     43\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     45\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     46\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/progetto_tesi/venv/lib/python3.9/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/progetto_tesi/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/progetto_tesi/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/progetto_tesi/venv/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/progetto_tesi/venv/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[5], line 15\u001b[0m, in \u001b[0;36mCWT_Dataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     13\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_dir, file_name)\n\u001b[1;32m     14\u001b[0m cwt_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(file_path)\n\u001b[0;32m---> 15\u001b[0m cwt_data \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcwt_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m cwt_data \u001b[38;5;241m=\u001b[39m cwt_data\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cwt_data, label\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, val_loader, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
